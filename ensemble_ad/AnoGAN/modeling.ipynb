{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51a3e442-5e7f-40ef-91f0-6dd7c0dd71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.AnoGAN import AnoGAN\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchmetrics.functional.classification import binary_auroc, binary_accuracy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2562e43b-1730-4fee-9563-f8b90df4be3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR10(root='data/', download=True, transform=ToTensor())\n",
    "test_dataset = CIFAR10(root='data/', train=False, transform=ToTensor())\n",
    "\n",
    "label = 1\n",
    "dataset.targets = (torch.Tensor(dataset.targets) == label).type(torch.float)\n",
    "test_dataset.targets = (torch.Tensor(test_dataset.targets) == label).type(torch.float)\n",
    "\n",
    "# dataset = torch.utils.data.Subset(dataset, (dataset.targets == label).nonzero(as_tuple=True)[0])\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, range(1250))\n",
    "batch_size = 250\n",
    "train_loader = DataLoader(dataset, batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7017491-d7be-4638-9b24-3b72515e0868",
   "metadata": {},
   "outputs": [],
   "source": [
    "anogan = AnoGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10179948-765f-469a-94e7-edef02fcad49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Epoch 0: Total Accuracy: 0.9184000015258789 Focal Accuracy: 0.29833329021930693 AUROC: 0.9177510738372803<p>Epoch 1: Total Accuracy: 0.9263999998569489 Focal Accuracy: 0.6355910420417785 AUROC: 0.961833143234253<p>Epoch 2: Total Accuracy: 0.9333333333333333 Focal Accuracy: 0.5747609496116638 AUROC: 0.9589463472366333<p>Epoch 3: Total Accuracy: 0.9365999966859817 Focal Accuracy: 0.5110309422016144 AUROC: 0.9763551354408264<p>Epoch 4: Total Accuracy: 0.9396799945831299 Focal Accuracy: 0.6645984888076782 AUROC: 0.9720054268836975<p>Epoch 5: Total Accuracy: 0.9431999941666921 Focal Accuracy: 0.7912705779075623 AUROC: 0.9791146159172058<p>Epoch 6: Total Accuracy: 0.9458285655294146 Focal Accuracy: 0.8636351108551026 AUROC: 0.9795281887054443<p>Epoch 7: Total Accuracy: 0.9480999931693077 Focal Accuracy: 0.8939612030982971 AUROC: 0.9826369285583496<p>Epoch 8: Total Accuracy: 0.9505777716636657 Focal Accuracy: 0.777201509475708 AUROC: 0.9885549664497375<p>Epoch 9: Total Accuracy: 0.9524799931049347 Focal Accuracy: 0.8539479613304138 AUROC: 0.9834622263908386<p>Epoch 10: Total Accuracy: 0.9545454491268505 Focal Accuracy: 0.869892132282257 AUROC: 0.9877496838569642<p>Epoch 11: Total Accuracy: 0.9557333290576935 Focal Accuracy: 0.7866439580917358 AUROC: 0.9834399104118348<p>Epoch 12: Total Accuracy: 0.9570461502441994 Focal Accuracy: 0.8446688890457154 AUROC: 0.9854514837265015<p>Epoch 13: Total Accuracy: 0.9579999966280801 Focal Accuracy: 0.8158799409866333 AUROC: 0.9843289375305175<p>Epoch 14: Total Accuracy: 0.9591466641426086 Focal Accuracy: 0.8796417832374572 AUROC: 0.9916326999664307<p>Epoch 15: Total Accuracy: 0.9601499974727631 Focal Accuracy: 0.8588707566261291 AUROC: 0.9875171184539795<p>Epoch 16: Total Accuracy: 0.9609411737498115 Focal Accuracy: 0.9103314399719238 AUROC: 0.9874513506889343<p>Epoch 17: Total Accuracy: 0.9618222196896871 Focal Accuracy: 0.8865383386611938 AUROC: 0.9912652015686035<p>Epoch 18: Total Accuracy: 0.961852628933756 Focal Accuracy: 0.757677698135376 AUROC: 0.9810001015663147<p>Epoch 19: Total Accuracy: 0.9619599974155426 Focal Accuracy: 0.6686502695083618 AUROC: 0.9852964639663696"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 20\n",
    "mb = master_bar(range(epochs))\n",
    "AUROC_converg = []\n",
    "ACC_converg = []\n",
    "total_acc = []\n",
    "for epoch in mb:\n",
    "    for j,(image,y) in enumerate(progress_bar(train_loader, parent = mb)):\n",
    "        auroc, acc, g_loss, d_loss, fake, real = anogan.train(image, y, verbose = True)\n",
    "        mb.child.comment = \"gen_loss: {} dis_loss: {} fake: {} real: {}\".format(g_loss, d_loss, fake, real)\n",
    "    \n",
    "    batch_auroc = []\n",
    "    batch_acc = []\n",
    "    for j,(batch,y) in enumerate(progress_bar(test_loader, parent = mb)):  \n",
    "        preds, auroc, acc, g_loss, d_loss, fake, real = anogan.predict(batch, y, verbose = True)\n",
    "        batch_auroc.append(float(auroc.data))\n",
    "        batch_acc.append(float(acc.data))\n",
    "        total_acc.append(float(binary_accuracy(preds, y).data))\n",
    "    AUROC_converg.append(sum(batch_auroc) / len(batch_auroc))\n",
    "    ACC_converg.append(sum (batch_acc) / len (batch_acc))\n",
    "    mb.main_bar.comment = \"AUROC: {} ACC:{}\".format(sum(batch_auroc) / len(batch_auroc), sum(batch_acc) / len(batch_acc))\n",
    "    \n",
    "    mb.write('Epoch {}: Total Accuracy: {} Focal Accuracy: {} AUROC: {}'.format(epoch, \n",
    "                                                                                   sum(total_acc) / len(total_acc),\n",
    "                                                                                   sum(batch_acc) / len(batch_acc),\n",
    "                                                                                   sum(batch_auroc) / len(batch_auroc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "021c35c3-b47b-429a-bd4a-a4c3f3b308c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(anogan, \"AnoGAN_model_20_full.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d69c3-0b6a-4b69-a834-d660c78b2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUROC_converg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9097318a-4be0-43b7-9f58-47f21e649159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VotingClassifier(input1, input2, input3, threshold = 0.5):\n",
    "    return torch.mode(torch.where(torch.concat((input1, input2, input3), dim = 1)>threshold, 1.,0.)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9a2e1f-be76-4d75-b879-108ba1744b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageClassifier(input1, input2, input3, threshold = 0.5):\n",
    "    return torch.where(torch.mean(torch.concat((input1, input2, input3), dim = 1), dim =1)>threshold, 1.,0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e358f-f75b-48e8-a39c-d4071875b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearEnsemble(nn.Module):\n",
    "    def __init__(self, anoGAN, secondModel):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.anoGAN = anoGAN.D.forward\n",
    "        self.secondModel = modelB\n",
    "        self.classifier = nn.Linear(in_features, 1) #define accordingly\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.firstModel(x1)\n",
    "        x2 = self.secondModel(x2)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.classifier(self.relu(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb53bf-caa3-4ceb-8ec4-5e46440551df",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.rand(250, 1)\n",
    "input2 = torch.rand(250, 1)\n",
    "input3 = torch.rand(250, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54b051a1-9948-4f88-8f31-809b7dae9f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnoGAN(\n",
       "  (loss): BCELoss()\n",
       "  (G): Generator(\n",
       "    (layer_0): Sequential(\n",
       "      (0): ConvTranspose2d(100, 1024, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer_1): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer_2): Sequential(\n",
       "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer_3): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer_4): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer_5): Sequential(\n",
       "      (0): ConvTranspose2d(64, 3, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       "  (D): Discriminator(\n",
       "    (layer_0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (layer_1): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (layer_2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (layer_3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (layer_4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (layer_5): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (fully_connected): Sequential(\n",
       "      (0): Conv2d(1024, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"C:\\\\Users\\\\galli\\\\Documents\\\\GitHub\\\\cs7643_final_project\\\\ensemble_ad\\\\AnoGAN\\\\AnoGAN_model_0.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
